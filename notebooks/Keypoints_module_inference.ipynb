{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keypoints_module_inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mBKBn01Q02z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae14b6f1-01e1-43fc-e12b-b5b9d4ee956f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNW2EhE7LurT"
      },
      "source": [
        "import numpy as np\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "import sys\r\n",
        "import time\r\n",
        "\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "\r\n",
        "module_dir = '/content/drive/MyDrive/pose_estimation/keypoint_module/'\r\n",
        "\r\n",
        "sys.path.append(module_dir)\r\n",
        "\r\n",
        "from models.yolo import *\r\n",
        "from models.hrnet import *\r\n",
        "from utils.detector import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKOtIjA0Lqd2"
      },
      "source": [
        "def predict(file_path, pred_path, module_dir, draw_bbox=False, box_tr=0.7):\r\n",
        "\r\n",
        "  # file_path - absolute path to file\r\n",
        "  # pred_path - absolute path for prediction\r\n",
        "  # module_dir - path for module folder\r\n",
        "  # draw_bbox - draw bboxes or not\r\n",
        "  # box_tr - threshold for bbox confidence\r\n",
        "\r\n",
        "  image_formats = ['.jpg', '.png', '.jpeg', '.bmp']\r\n",
        "  video_formats = ['.mp4', '.mov', '.avi', '.webm', '.mkv', '.m4v']\r\n",
        "  file_format = file_path[file_path.rindex('.'):].lower()\r\n",
        "\r\n",
        "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "  yolov5 = load_yolo_model(module_dir).to(device)\r\n",
        "  keypoint_net = load_keypoint_net(module_dir).to(device)\r\n",
        "\r\n",
        "  if file_format in image_formats:\r\n",
        "    \r\n",
        "    pred_path = predict_image(file_path, pred_path, yolov5, keypoint_net, device,\r\n",
        "                              draw_bbox=draw_bbox, box_tr=box_tr)\r\n",
        "\r\n",
        "  elif file_format in video_formats:\r\n",
        "\r\n",
        "    pred_path = predict_video(file_path, pred_path, yolov5, keypoint_net, device,\r\n",
        "                              draw_bbox=draw_bbox, box_tr=box_tr)\r\n",
        "\r\n",
        "  else:\r\n",
        "    print('Unknown file format')\r\n",
        "\r\n",
        "  return pred_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw7wPL2qHWvo"
      },
      "source": [
        "files_dir = '/content/drive/MyDrive/pose_estimation/keypoint_module/test_examples/'\r\n",
        "result_dir = '/content/drive/MyDrive/pose_estimation/keypoint_module/results/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej7BbdO5HHnW",
        "outputId": "b63f4d93-3e09-402e-ec8b-90f48618b07f"
      },
      "source": [
        "for filename in os.listdir(files_dir):\r\n",
        "  curr_time = time.time()\r\n",
        "  file_path = os.path.join(files_dir, filename)\r\n",
        "  pred_path = result_dir + file_path[file_path.rindex('/')+1:file_path.rindex('.')]+'_predict.webm'\r\n",
        "  pred_path = predict(file_path, pred_path, module_dir)\r\n",
        "  print(pred_path, '--  ready, time:', round(time.time() - curr_time), 's')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py:390: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  if param.grad is not None:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/pose_estimation/keypoint_module/results/hands1_predict.webm --  ready, time: 40 s\n",
            "/content/drive/MyDrive/pose_estimation/keypoint_module/results/hands2_predict.webm --  ready, time: 14 s\n",
            "/content/drive/MyDrive/pose_estimation/keypoint_module/results/hands5_predict.webm --  ready, time: 16 s\n",
            "/content/drive/MyDrive/pose_estimation/keypoint_module/results/hands6_predict.webm --  ready, time: 18 s\n",
            "/content/drive/MyDrive/pose_estimation/keypoint_module/results/hands7_predict.webm --  ready, time: 19 s\n",
            "/content/drive/MyDrive/pose_estimation/keypoint_module/results/hands10_predict.webm --  ready, time: 21 s\n",
            "/content/drive/MyDrive/pose_estimation/keypoint_module/results/hands11_predict.webm --  ready, time: 19 s\n",
            "/content/drive/MyDrive/pose_estimation/keypoint_module/results/hands12_predict.webm --  ready, time: 16 s\n",
            "/content/drive/MyDrive/pose_estimation/keypoint_module/results/hands14_predict.webm --  ready, time: 22 s\n",
            "/content/drive/MyDrive/pose_estimation/keypoint_module/results/hands4_predict.webm --  ready, time: 17 s\n",
            "/content/drive/MyDrive/pose_estimation/keypoint_module/results/hands3_predict.webm --  ready, time: 17 s\n",
            "/content/drive/MyDrive/pose_estimation/keypoint_module/results/hands8_predict.webm --  ready, time: 19 s\n",
            "/content/drive/MyDrive/pose_estimation/keypoint_module/results/hands9_predict.webm --  ready, time: 15 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIn86ZYFHxVW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}